{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from gensim import corpora, models\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    tokens = doc.split()\n",
    "    tokens = [t for t in tokens if t.lower() not in stopwords]\n",
    "    tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('shakespeare-complete-raw.txt'):\n",
    "    print('downloading shakespeare text...')\n",
    "    url = 'https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt'\n",
    "    response = request.urlopen(url)\n",
    "    raw = response.read().decode('utf8')\n",
    "    with open('shakespeare-complete-raw.txt', 'w') as o:\n",
    "        o.write(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sonnets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing text...\n"
     ]
    }
   ],
   "source": [
    "print('processing text...')\n",
    "text = open('shakespeare-complete-raw.txt').read()\n",
    "sonnets_complete = text[text.find('THE SONNETS'):text.find('THE END')]\n",
    "sonnets = sonnets_complete.split('\\n\\n\\n')\n",
    "sonnets = [tokenize(s) for s in sonnets]\n",
    "sonnets = sonnets[1:-1]  # remove the first and last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(sonnets)\n",
    "# dictionary.filter_extremes(no_above=0.25)\n",
    "dictionary.filter_n_most_frequent(200)\n",
    "\n",
    "corpus = [dictionary.doc2bow(sonnet) for sonnet in sonnets]\n",
    "\n",
    "print('training model...')\n",
    "model = models.LdaModel(corpus, id2word=dictionary, num_topics=20)\n",
    "\n",
    "topics = model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011*\"lips\" + 0.010*\"three\" + 0.007*\"jacks\" + 0.007*\"fingers\" + 0.007*\"wood\" + 0.007*\"minds\" + 0.007*\"alters\" + 0.005*\"edge\" + 0.005*\"blest\" + 0.005*\"answer\"\n",
      "\n",
      "0.007*\"reason\" + 0.007*\"large\" + 0.007*\"sooner\" + 0.007*\"add\" + 0.007*\"tongues\" + 0.007*\"hawks\" + 0.007*\"lust\" + 0.006*\"spite\" + 0.006*\"bare\" + 0.005*\"want\"\n",
      "\n",
      "0.008*\"hence\" + 0.008*\"sweetest\" + 0.008*\"minutes\" + 0.008*\"whether\" + 0.008*\"main\" + 0.008*\"mind\" + 0.008*\"memory\" + 0.005*\"yield\" + 0.004*\"toil\" + 0.004*\"thrive\"\n",
      "\n",
      "0.018*\"angel\" + 0.012*\"excuse\" + 0.008*\"reason\" + 0.008*\"haste\" + 0.008*\"dull\" + 0.007*\"head\" + 0.006*\"woe\" + 0.005*\"work\" + 0.005*\"fire\" + 0.004*\"duty\"\n",
      "\n",
      "0.008*\"whether\" + 0.006*\"fire\" + 0.005*\"lovers\" + 0.005*\"antique\" + 0.005*\"took\" + 0.005*\"obsequious\" + 0.005*\"came\" + 0.005*\"pluck\" + 0.005*\"laid\" + 0.005*\"former\"\n",
      "\n",
      "0.014*\"soul\" + 0.010*\"check\" + 0.010*\"pride\" + 0.010*\"case\" + 0.010*\"number\" + 0.007*\"catch\" + 0.006*\"babe\" + 0.006*\"turn\" + 0.006*\"flies\" + 0.005*\"repose\"\n",
      "\n",
      "0.009*\"absence\" + 0.007*\"dare\" + 0.006*\"shadow\" + 0.006*\"says\" + 0.006*\"stay\" + 0.006*\"slave\" + 0.006*\"lends\" + 0.006*\"title\" + 0.006*\"due\" + 0.005*\"torment\"\n",
      "\n",
      "0.009*\"wound\" + 0.007*\"painting\" + 0.006*\"reasons\" + 0.006*\"strength\" + 0.006*\"mightst\" + 0.006*\"friend\" + 0.006*\"pretty\" + 0.006*\"lead\" + 0.005*\"errors\" + 0.005*\"whereto\"\n",
      "\n",
      "0.010*\"winter\" + 0.007*\"gift\" + 0.007*\"sometime\" + 0.006*\"hear\" + 0.006*\"cause\" + 0.006*\"strength\" + 0.006*\"buds\" + 0.006*\"play\" + 0.006*\"alone\" + 0.006*\"gracious\"\n",
      "\n",
      "0.011*\"seen\" + 0.010*\"words\" + 0.010*\"mad\" + 0.009*\"sometime\" + 0.005*\"delight\" + 0.005*\"news\" + 0.005*\"press\" + 0.005*\"ears\" + 0.005*\"grown\" + 0.005*\"testy\"\n",
      "\n",
      "0.012*\"wherefore\" + 0.006*\"set\" + 0.006*\"place\" + 0.006*\"painted\" + 0.006*\"widow\" + 0.006*\"seeming\" + 0.006*\"says\" + 0.006*\"compare\" + 0.006*\"believe\" + 0.006*\"dull\"\n",
      "\n",
      "0.011*\"sake\" + 0.010*\"conscience\" + 0.010*\"friend\" + 0.008*\"wert\" + 0.007*\"soul\" + 0.006*\"mind\" + 0.006*\"body\" + 0.006*\"loss\" + 0.006*\"touches\" + 0.006*\"gross\"\n",
      "\n",
      "0.009*\"sweets\" + 0.008*\"oaths\" + 0.007*\"music\" + 0.006*\"needs\" + 0.005*\"fast\" + 0.005*\"breath\" + 0.005*\"hadst\" + 0.005*\"comments\" + 0.005*\"sworn\" + 0.005*\"faith\"\n",
      "\n",
      "0.016*\"three\" + 0.010*\"swift\" + 0.010*\"seldom\" + 0.008*\"bath\" + 0.008*\"fell\" + 0.006*\"cupid\" + 0.006*\"help\" + 0.005*\"fire\" + 0.005*\"brand\" + 0.005*\"straight\"\n",
      "\n",
      "0.011*\"write\" + 0.009*\"sin\" + 0.007*\"invention\" + 0.006*\"sins\" + 0.005*\"shows\" + 0.005*\"riper\" + 0.005*\"needs\" + 0.005*\"creatures\" + 0.005*\"vanished\" + 0.005*\"morn\"\n",
      "\n",
      "0.028*\"ten\" + 0.009*\"happier\" + 0.009*\"treasure\" + 0.009*\"wish\" + 0.005*\"grows\" + 0.005*\"takes\" + 0.005*\"madding\" + 0.005*\"woo\" + 0.005*\"fitted\" + 0.005*\"scarlet\"\n",
      "\n",
      "0.010*\"seest\" + 0.007*\"whereon\" + 0.007*\"care\" + 0.006*\"thence\" + 0.005*\"tomb\" + 0.005*\"twice\" + 0.005*\"second\" + 0.005*\"late\" + 0.005*\"poet\" + 0.005*\"antique\"\n",
      "\n",
      "0.011*\"picture\" + 0.007*\"painter\" + 0.007*\"windows\" + 0.007*\"turns\" + 0.007*\"five\" + 0.006*\"rage\" + 0.005*\"errors\" + 0.005*\"holds\" + 0.005*\"wherein\" + 0.005*\"sets\"\n",
      "\n",
      "0.009*\"nightly\" + 0.007*\"giving\" + 0.005*\"seeking\" + 0.005*\"fairer\" + 0.005*\"enemies\" + 0.005*\"eased\" + 0.005*\"benefit\" + 0.005*\"length\" + 0.005*\"hands\" + 0.005*\"possessed\"\n",
      "\n",
      "0.007*\"sick\" + 0.007*\"honour\" + 0.006*\"flower\" + 0.005*\"forth\" + 0.005*\"basest\" + 0.005*\"altered\" + 0.004*\"disgrace\" + 0.004*\"acquaintance\" + 0.004*\"haply\" + 0.004*\"straight\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(topic[1])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
